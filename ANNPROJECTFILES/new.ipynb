{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eac17a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c1a3914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "folder_path = '/Users/yashp/OneDrive/Desktop/resizetrain/Resize3/'\n",
    "img_list=[]\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.jpg'):  # Assuming all files are PNG images\n",
    "        img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        img_array = np.array(img)\n",
    "        img_list.append(img_array)\n",
    "    \n",
    "        #print('Array shape:', img_array.shape)\n",
    "        #print('Array type:', img_array.dtype)\n",
    "    \n",
    "#print(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75eb39d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffed1a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array=np.array(img_list,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3dc03752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 16, 16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4136e6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[224, 216, 211, ..., 198, 194, 186],\n",
       "        [220, 204, 176, ..., 198, 196, 189],\n",
       "        [205, 177, 137, ..., 202, 196, 196],\n",
       "        ...,\n",
       "        [228, 219, 212, ..., 198, 197, 188],\n",
       "        [232, 226, 221, ..., 194, 197, 185],\n",
       "        [237, 229, 224, ..., 197, 185, 182]],\n",
       "\n",
       "       [[196, 196, 203, ..., 197, 197, 188],\n",
       "        [198, 195, 209, ..., 202, 196, 196],\n",
       "        [205, 207, 103, ..., 207, 200, 198],\n",
       "        ...,\n",
       "        [210, 194, 146, ..., 209, 214, 215],\n",
       "        [221, 208, 193, ..., 217, 217, 228],\n",
       "        [225, 223, 186, ..., 223, 227, 227]],\n",
       "\n",
       "       [[219, 206, 192, ..., 199, 199, 194],\n",
       "        [191, 183, 112, ..., 205, 202, 198],\n",
       "        [159, 82, 77, ..., 114, 202, 201],\n",
       "        ...,\n",
       "        [228, 213, 198, ..., 200, 199, 195],\n",
       "        [229, 227, 214, ..., 201, 196, 193],\n",
       "        [234, 229, 224, ..., 199, 192, 186]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[231, 228, 222, ..., 180, 211, 216],\n",
       "        [223, 223, 211, ..., 169, 192, 208],\n",
       "        [222, 212, 204, ..., 147, 51, 196],\n",
       "        ...,\n",
       "        [199, 200, 200, ..., 92, 30, 198],\n",
       "        [191, 196, 202, ..., 215, 195, 200],\n",
       "        [187, 188, 192, ..., 194, 198, 195]],\n",
       "\n",
       "       [[180, 186, 196, ..., 215, 227, 232],\n",
       "        [186, 194, 202, ..., 218, 221, 227],\n",
       "        [192, 202, 202, ..., 214, 218, 225],\n",
       "        ...,\n",
       "        [202, 215, 24, ..., 17, 119, 206],\n",
       "        [203, 55, 26, ..., 182, 207, 220],\n",
       "        [202, 201, 204, ..., 202, 215, 226]],\n",
       "\n",
       "       [[201, 207, 201, ..., 196, 193, 187],\n",
       "        [209, 40, 23, ..., 203, 203, 194],\n",
       "        [198, 77, 156, ..., 203, 201, 194],\n",
       "        ...,\n",
       "        [196, 180, 162, ..., 194, 215, 220],\n",
       "        [212, 176, 123, ..., 215, 219, 223],\n",
       "        [222, 214, 198, ..., 224, 226, 229]]], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70a1429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "folder_path = '/Users/yashp/OneDrive/Desktop/resizetest/resize3/'\n",
    "test_list=[]\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.jpg'): \n",
    "        img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        img_array = np.array(img)\n",
    "        test_list.append(img_array)\n",
    "\n",
    "        #print('Array shape:', img_array.shape)\n",
    "        #print('Array type:', img_array.dtype)\n",
    "\n",
    "        \n",
    "#print(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "001d73be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c220b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array=np.array(test_list,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb903347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 16, 16)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e666c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[221, 220, 207, ..., 200, 201, 194],\n",
       "        [221, 199, 186, ..., 205, 198, 199],\n",
       "        [204, 178, 109, ..., 143, 203, 200],\n",
       "        ...,\n",
       "        [226, 223, 212, ..., 202, 198, 204],\n",
       "        [234, 230, 225, ..., 210, 200, 195],\n",
       "        [233, 230, 226, ..., 199, 198, 200]],\n",
       "\n",
       "       [[201, 200, 206, ..., 195, 193, 188],\n",
       "        [204, 209, 212, ..., 203, 198, 194],\n",
       "        [212, 212, 211, ..., 212, 210, 198],\n",
       "        ...,\n",
       "        [198, 190, 184, ..., 218, 219, 229],\n",
       "        [211, 201, 181, ..., 221, 226, 229],\n",
       "        [218, 211, 192, ..., 226, 236, 233]],\n",
       "\n",
       "       [[226, 219, 214, ..., 208, 203, 195],\n",
       "        [222, 213, 197, ..., 212, 205, 200],\n",
       "        [214, 190, 182, ..., 201, 213, 201],\n",
       "        ...,\n",
       "        [226, 224, 214, ..., 202, 195, 191],\n",
       "        [230, 224, 219, ..., 195, 200, 189],\n",
       "        [238, 229, 223, ..., 195, 187, 183]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[193, 195, 198, ..., 195, 194, 188],\n",
       "        [195, 199, 200, ..., 201, 196, 196],\n",
       "        [199, 205, 205, ..., 201, 203, 198],\n",
       "        ...,\n",
       "        [164, 83, 57, ..., 200, 180, 216],\n",
       "        [204, 180, 83, ..., 205, 217, 225],\n",
       "        [219, 196, 60, ..., 219, 230, 231]],\n",
       "\n",
       "       [[216, 206, 190, ..., 194, 191, 188],\n",
       "        [208, 178, 173, ..., 201, 196, 188],\n",
       "        [188, 133, 83, ..., 204, 196, 196],\n",
       "        ...,\n",
       "        [223, 224, 210, ..., 198, 192, 187],\n",
       "        [227, 224, 218, ..., 191, 193, 183],\n",
       "        [230, 227, 221, ..., 191, 183, 179]],\n",
       "\n",
       "       [[234, 226, 229, ..., 193, 214, 217],\n",
       "        [227, 226, 220, ..., 163, 182, 208],\n",
       "        [224, 218, 207, ..., 41, 171, 192],\n",
       "        ...,\n",
       "        [190, 199, 203, ..., 217, 209, 206],\n",
       "        [191, 191, 197, ..., 206, 201, 202],\n",
       "        [179, 189, 190, ..., 201, 195, 194]]], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "326bcb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flat = train_array.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e70e8691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x: Input data. It could be:\\n      - A Numpy array (or array-like), or a list of arrays\\n        (in case the model has multiple inputs).\\n      - A TensorFlow tensor, or a list of tensors\\n        (in case the model has multiple inputs).\\n      - A dict mapping input names to the corresponding array/tensors,\\n        if the model has named inputs.\\n      - A `tf.data` dataset. Should return a tuple\\n        of either `(inputs, targets)` or\\n        `(inputs, targets, sample_weights)`.\\n      - A generator or `keras.utils.Sequence` returning `(inputs,\\n        targets)` or `(inputs, targets, sample_weights)`.\\n      - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a\\n        callable that takes a single argument of type\\n        `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.\\n        `DatasetCreator` should be used when users prefer to specify the\\n        per-replica batching and sharding logic for the `Dataset`.\\n        See `tf.keras.utils.experimental.DatasetCreator` doc for more\\n        information.\\n      A more detailed description of unpacking behavior for iterator\\n      types (Dataset, generator, Sequence) is given below. If these\\n      include `sample_weights` as a third component, note that sample\\n      weighting applies to the `weighted_metrics` argument but not the\\n      `metrics` argument in `compile()`. If using\\n      `tf.distribute.experimental.ParameterServerStrategy`, only\\n      `DatasetCreator` type is supported for `x`.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''x: Input data. It could be:\n",
    "      - A Numpy array (or array-like), or a list of arrays\n",
    "        (in case the model has multiple inputs).\n",
    "      - A TensorFlow tensor, or a list of tensors\n",
    "        (in case the model has multiple inputs).\n",
    "      - A dict mapping input names to the corresponding array/tensors,\n",
    "        if the model has named inputs.\n",
    "      - A `tf.data` dataset. Should return a tuple\n",
    "        of either `(inputs, targets)` or\n",
    "        `(inputs, targets, sample_weights)`.\n",
    "      - A generator or `keras.utils.Sequence` returning `(inputs,\n",
    "        targets)` or `(inputs, targets, sample_weights)`.\n",
    "      - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a\n",
    "        callable that takes a single argument of type\n",
    "        `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.\n",
    "        `DatasetCreator` should be used when users prefer to specify the\n",
    "        per-replica batching and sharding logic for the `Dataset`.\n",
    "        See `tf.keras.utils.experimental.DatasetCreator` doc for more\n",
    "        information.\n",
    "      A more detailed description of unpacking behavior for iterator\n",
    "      types (Dataset, generator, Sequence) is given below. If these\n",
    "      include `sample_weights` as a third component, note that sample\n",
    "      weighting applies to the `weighted_metrics` argument but not the\n",
    "      `metrics` argument in `compile()`. If using\n",
    "      `tf.distribute.experimental.ParameterServerStrategy`, only\n",
    "      `DatasetCreator` type is supported for `x`.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dc2f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_flat = test_array.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d05b9bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab75f963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15360,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46b2926c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10240,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58009e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = train_flat.reshape((1,15360))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9402783a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15360,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba423ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flat = np.asarray(train_flat).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5eb12992",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = np.asarray(train_array).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1aa981d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93c18e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\yashp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\yashp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\yashp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\yashp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1025, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"C:\\Users\\yashp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 979, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: Target data is missing. Your model was compiled with loss=sparse_categorical_crossentropy, and therefore expects target data to be provided in `fit()`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5624\\896901487.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\yashp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\yashp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\yashp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\yashp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1025, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"C:\\Users\\yashp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 979, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: Target data is missing. Your model was compiled with loss=sparse_categorical_crossentropy, and therefore expects target data to be provided in `fit()`.\n"
     ]
    }
   ],
   "source": [
    "ann = models.Sequential([\n",
    "        #layers.Flatten(input_shape=(60,16,16)),\n",
    "        layers.Dense(3000, activation='relu'),\n",
    "        layers.Dense(1000, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')    \n",
    "    ])\n",
    "\n",
    "ann.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "ann.fit(train_array,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8013a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=[1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49aae680",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=[1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "435745fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=np.asarray(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c2a1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=np.asarray(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fda2cc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a2ac228",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 60\n  y sizes: 3\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5624\\2578317395.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtst_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1846\u001b[0m             )\n\u001b[0;32m   1847\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 60\n  y sizes: 3\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(16, 16, 60)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(arr, train_labels, epochs=10, batch_size=16, validation_data=(tst_arr, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image file names into a list\n",
    "image_files = [\"image1.jpg\", \"image2.jpg\", \"image3.jpg\"]\n",
    "\n",
    "# Load the images and convert them to a NumPy array\n",
    "images = [cv2.imread(filename) for filename in image_files]\n",
    "images = np.asarray(images)\n",
    "\n",
    "# Pass the NumPy array to the Keras model for training or prediction\n",
    "model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db7076c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/yashp/OneDrive/Desktop/resizetrain/Resize3/'\n",
    "img_list=[]\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.jpg'):  # Assuming all files are PNG images\n",
    "        img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        img_array = np.array(img)\n",
    "        img_list.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc26afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=np.asarray(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bbafab85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 16, 16)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77d7f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/yashp/OneDrive/Desktop/resizetest/resize3/'\n",
    "tst_list=[]\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.jpg'):  # Assuming all files are PNG images\n",
    "        img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        img_array = np.array(img)\n",
    "        tst_list.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fad12dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_arr=np.asarray(tst_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78cd3245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316c921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
